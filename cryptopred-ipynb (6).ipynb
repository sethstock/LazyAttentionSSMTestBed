{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96164,"databundleVersionId":11418275,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import polars as pl\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\n\nNUM_DAYS = 7\n\n# Step 1: Get max timestamp from the file (only this column is scanned)\nlatest_ts = (\n    pl.scan_parquet(\"/kaggle/input/drw-crypto-market-prediction/train.parquet\")\n    .select(pl.col(\"timestamp\").max())\n    .collect()\n    .item()\n)\n\n# Step 2: Calculate cutoff timestamp\ncutoff_ts = latest_ts - pl.duration(days=NUM_DAYS)\n\n# Step 3: Lazily scan, filter, and sort\nlf = pl.scan_parquet(\"/kaggle/input/drw-crypto-market-prediction/train.parquet\")\nlf_filtered = lf.filter(pl.col(\"timestamp\") >= cutoff_ts)\n","metadata":{"_cell_guid":"1bb5dee9-60aa-4f92-88e1-3e46479f8d01","_uuid":"81e716e2-29a9-4755-892b-2fe8c7b98313","collapsed":false,"execution":{"iopub.status.busy":"2025-06-17T22:05:35.451141Z","iopub.execute_input":"2025-06-17T22:05:35.451925Z","iopub.status.idle":"2025-06-17T22:05:41.422076Z","shell.execute_reply.started":"2025-06-17T22:05:35.451892Z","shell.execute_reply":"2025-06-17T22:05:41.421307Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = lf_filtered.collect().sort(\"timestamp\")","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:41.423221Z","iopub.execute_input":"2025-06-17T22:05:41.423637Z","iopub.status.idle":"2025-06-17T22:05:52.181883Z","shell.execute_reply.started":"2025-06-17T22:05:41.423611Z","shell.execute_reply":"2025-06-17T22:05:52.181124Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop timestamp — it's not used directly by the model\nfeatures = train.drop([\"timestamp\", \"label\"])\ntarget = train[\"label\"]\nX = features.to_numpy()\ny = target.to_numpy()\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:52.182655Z","iopub.execute_input":"2025-06-17T22:05:52.182863Z","iopub.status.idle":"2025-06-17T22:05:52.216238Z","shell.execute_reply.started":"2025-06-17T22:05:52.182848Z","shell.execute_reply":"2025-06-17T22:05:52.215594Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Replace inf/-inf with NaN\nX[np.isinf(X)] = np.nan\n\n# Step 2: Drop columns with all NaNs\nvalid_cols = ~np.isnan(X).all(axis=0)\nX = X[:, valid_cols]\n\n# Step 3: Impute remaining NaNs with column means\ncol_means = np.nanmean(X, axis=0)\ninds = np.where(np.isnan(X))\nX[inds] = np.take(col_means, inds[1])\n\n# Now scale\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:52.217977Z","iopub.execute_input":"2025-06-17T22:05:52.218234Z","iopub.status.idle":"2025-06-17T22:05:53.246361Z","shell.execute_reply.started":"2025-06-17T22:05:52.218217Z","shell.execute_reply":"2025-06-17T22:05:53.245578Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nLOOKBACK = 45    # 1 hour of minute data\nHORIZON = 10    # predict 15 minutes into the future\nBATCH_SIZE = 32\n\ndef make_windows(X, y, lookback=LOOKBACK, horizon=HORIZON):\n    Xs, Ys = [], []\n    for i in range(len(X) - lookback - horizon):\n        Xs.append(X[i:i+lookback])\n        Ys.append(y[i+lookback + horizon - 1])\n    return np.stack(Xs), np.array(Ys)\n\nX_seq, y_seq = make_windows(X_scaled, y)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:53.247221Z","iopub.execute_input":"2025-06-17T22:05:53.247606Z","iopub.status.idle":"2025-06-17T22:05:54.085170Z","shell.execute_reply.started":"2025-06-17T22:05:53.247578Z","shell.execute_reply":"2025-06-17T22:05:54.084380Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import Dataset\n\nclass CryptoDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ndataset = CryptoDataset(X_seq, y_seq)\n\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:54.086206Z","iopub.execute_input":"2025-06-17T22:05:54.086432Z","iopub.status.idle":"2025-06-17T22:05:54.841576Z","shell.execute_reply.started":"2025-06-17T22:05:54.086416Z","shell.execute_reply":"2025-06-17T22:05:54.840950Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import random_split, DataLoader\n\n# Total number of samples\ntotal_size = len(dataset)\n\n# Proportions\ntrain_pct = 0.7\nval_pct   = 0.3\n\n\n# Integer sizes\ntrain_size = int(train_pct * total_size)\nval_size   = int(total_size - train_size)\n\n\n# Split the dataset\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=32)\n\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:54.842296Z","iopub.execute_input":"2025-06-17T22:05:54.842588Z","iopub.status.idle":"2025-06-17T22:05:54.856958Z","shell.execute_reply.started":"2025-06-17T22:05:54.842566Z","shell.execute_reply":"2025-06-17T22:05:54.856442Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=8192):\n        super().__init__()\n        pos = torch.arange(0, max_len).unsqueeze(1)\n        div = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n        pe = torch.zeros(1, max_len, d_model)\n        pe[0, :, 0::2] = torch.sin(pos * div)\n        pe[0, :, 1::2] = torch.cos(pos * div)\n        self.register_buffer(\"pe\", pe)\n\n    def forward(self, x):\n        # Dynamically adjust positional encoding to match input sequence length\n        seq_len = x.size(1)\n        if seq_len > self.pe.size(1):\n            raise ValueError(f\"Input sequence length ({seq_len}) exceeds maximum positional encoding length ({self.pe.size(1)}).\")\n        return x + self.pe[:, :seq_len, :]","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:54.857585Z","iopub.execute_input":"2025-06-17T22:05:54.857786Z","iopub.status.idle":"2025-06-17T22:05:54.862921Z","shell.execute_reply.started":"2025-06-17T22:05:54.857770Z","shell.execute_reply":"2025-06-17T22:05:54.862273Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GatedSSMBlock(nn.Module):\n    def __init__(self, d_model, dropout=0.2):\n        super().__init__()\n        self.U = nn.Linear(d_model, d_model)\n        self.F = nn.Linear(d_model, d_model)\n        self.O = nn.Linear(d_model, d_model)\n        self.norm = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        forget_gate = torch.sigmoid(self.F(x))\n        update = torch.tanh(self.U(x))\n        output_gate = torch.sigmoid(self.O(x))\n        h = forget_gate * x + (1 - forget_gate) * update\n        return self.dropout(self.norm(output_gate * h))\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:54.863648Z","iopub.execute_input":"2025-06-17T22:05:54.863805Z","iopub.status.idle":"2025-06-17T22:05:54.878896Z","shell.execute_reply.started":"2025-06-17T22:05:54.863793Z","shell.execute_reply":"2025-06-17T22:05:54.878331Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CrossHeadRouter(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.attn_weights = nn.Parameter(torch.randn(num_heads, d_model))\n\n    def forward(self, head_outputs):\n        # head_outputs: list of (B, T, D)\n        stacked = torch.stack(head_outputs, dim=2)  # (B, T, H, D)\n        weights = torch.einsum('bthd,hd->bth', stacked, self.attn_weights)  # (B, T, H)\n        soft_weights = torch.softmax(weights, dim=-1).unsqueeze(-1)         # (B, T, H, 1)\n        fused = (stacked * soft_weights).sum(dim=2)                         # (B, T, D)\n        return fused\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:54.880934Z","iopub.execute_input":"2025-06-17T22:05:54.881347Z","iopub.status.idle":"2025-06-17T22:05:54.898149Z","shell.execute_reply.started":"2025-06-17T22:05:54.881324Z","shell.execute_reply":"2025-06-17T22:05:54.897657Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TokenWiseFeedForward(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, d_model * 2),\n            nn.GELU(),\n            nn.Linear(d_model * 2, d_model)\n        )\n\n    def forward(self, x):\n        return self.ffn(x)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:54.898829Z","iopub.execute_input":"2025-06-17T22:05:54.899074Z","iopub.status.idle":"2025-06-17T22:05:54.916937Z","shell.execute_reply.started":"2025-06-17T22:05:54.899054Z","shell.execute_reply":"2025-06-17T22:05:54.916161Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ParallelSSMHeads(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.heads = nn.ModuleList([GatedSSMBlock(d_model) for _ in range(num_heads)])\n        self.router = CrossHeadRouter(d_model, num_heads)\n        self.tokenwise_ffn = TokenWiseFeedForward(d_model)\n        self.norm = nn.LayerNorm(d_model)\n\n    def forward(self, x):\n        # x: (B, T, D)\n        head_outputs = [head(x) for head in self.heads]  # Each (B, T, D)\n        fused = self.router(head_outputs)                # (B, T, D) after soft alignment\n        fused = fused + self.tokenwise_ffn(fused)        # Add local dynamics\n        return self.norm(fused)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:55.328151Z","iopub.execute_input":"2025-06-17T22:05:55.328704Z","iopub.status.idle":"2025-06-17T22:05:55.333239Z","shell.execute_reply.started":"2025-06-17T22:05:55.328684Z","shell.execute_reply":"2025-06-17T22:05:55.332574Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiHeadSSM(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0\n        self.head_dim = d_model // num_heads\n        self.heads = nn.ModuleList([GatedSSMBlock(self.head_dim) for _ in range(num_heads)])\n        self.output_proj = nn.Linear(d_model, d_model)\n\n    def forward(self, x):\n        B, T, D = x.shape\n        x = x.view(B, T, len(self.heads), self.head_dim)\n        x = torch.stack([head(x[:, :, i, :]) for i, head in enumerate(self.heads)], dim=2)\n        x = x.view(B, T, D)\n        return self.output_proj(x)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:57.416446Z","iopub.execute_input":"2025-06-17T22:05:57.417173Z","iopub.status.idle":"2025-06-17T22:05:57.422635Z","shell.execute_reply.started":"2025-06-17T22:05:57.417147Z","shell.execute_reply":"2025-06-17T22:05:57.421865Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HybridBlock(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.parallel_ssm = ParallelSSMHeads(d_model, num_heads)\n        self.norm = nn.LayerNorm(d_model)\n\n    def forward(self, x):\n        x_ssm = self.parallel_ssm(x)\n        return self.norm(x + x_ssm)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:05:59.168586Z","iopub.execute_input":"2025-06-17T22:05:59.168866Z","iopub.status.idle":"2025-06-17T22:05:59.173134Z","shell.execute_reply.started":"2025-06-17T22:05:59.168847Z","shell.execute_reply":"2025-06-17T22:05:59.172552Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\nclass LazyAttentionSSM(nn.Module):\n    def __init__(self, input_dim, d_model=512, depth=4, num_heads=4):\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.pos_enc = PositionalEncoding(d_model)\n        self.blocks = nn.Sequential(*[HybridBlock(d_model, num_heads) for _ in range(depth)])\n        self.output_norm = nn.LayerNorm(d_model)           # ⬅ use correct variable\n        self.head_dropout = nn.Dropout(0.2)\n        self.head = nn.Linear(d_model, 1)\n\n    def forward(self, x):\n        x = self.input_proj(x)\n        x = self.pos_enc(x)\n        x = self.blocks(x)\n        x = self.output_norm(x)                            # ⬅ normalize features before pooling\n        x = x.mean(dim=1)                                  # global average pooling\n        x = self.head_dropout(x)\n        return self.head(x)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:06:01.165117Z","iopub.execute_input":"2025-06-17T22:06:01.165643Z","iopub.status.idle":"2025-06-17T22:06:01.171167Z","shell.execute_reply.started":"2025-06-17T22:06:01.165619Z","shell.execute_reply":"2025-06-17T22:06:01.170423Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\nclass SimpleTransformerBlock(nn.Module):\n    def __init__(self, d_model, num_heads, dropout=0.2):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, d_model * 2),\n            nn.GELU(),\n            nn.Linear(d_model * 2, d_model),\n            nn.Dropout(dropout)\n        )\n        self.norm2 = nn.LayerNorm(d_model)\n\n    def forward(self, x):\n        attn_out, _ = self.attn(x, x, x)\n        x = self.norm1(x + attn_out)\n        ffn_out = self.ffn(x)\n        x = self.norm2(x + ffn_out)\n        return x\n\nclass Transformer(nn.Module):\n    def __init__(self, input_dim, d_model=1024, depth=8, num_heads=8):\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.pos_enc = PositionalEncoding(d_model)\n        self.blocks = nn.Sequential(*[SimpleTransformerBlock(d_model, num_heads) for _ in range(depth)])\n        self.output_norm = nn.LayerNorm(d_model)\n        self.head_dropout = nn.Dropout(0.2)\n        self.head = nn.Linear(d_model, 1)\n\n    def forward(self, x):\n        x = self.input_proj(x)\n        x = self.pos_enc(x)\n        x = self.blocks(x)\n        x = self.output_norm(x)\n        x = x.mean(dim=1)\n        x = self.head_dropout(x)\n        return self.head(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T22:06:03.040977Z","iopub.execute_input":"2025-06-17T22:06:03.041653Z","iopub.status.idle":"2025-06-17T22:06:03.048980Z","shell.execute_reply.started":"2025-06-17T22:06:03.041629Z","shell.execute_reply":"2025-06-17T22:06:03.048325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = LazyAttentionSSM(input_dim=X.shape[-1]).to(device)\n\n\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:06:05.623459Z","iopub.execute_input":"2025-06-17T22:06:05.623752Z","iopub.status.idle":"2025-06-17T22:06:09.210801Z","shell.execute_reply.started":"2025-06-17T22:06:05.623733Z","shell.execute_reply":"2025-06-17T22:06:09.210079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\nNUM_EPOCHS = 25\n\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    total_loss = 0\n    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n        xb, yb = xb.to(device), yb.to(device)\n        if yb.ndim == 1:\n            yb = yb.unsqueeze(1)  # Ensure shape is [B, 1]\n        optimizer.zero_grad()\n        preds = model(xb)\n        loss = loss_fn(preds, yb)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=.5)\n\n        optimizer.step()\n        total_loss += loss.item()\n    \n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            if yb.ndim == 1:\n                yb = yb.unsqueeze(1)  # Ensure shape is [B, 1]\n            preds = model(xb)\n            val_loss += loss_fn(preds, yb).item()\n\n    print(f\"Train Loss: {total_loss/len(train_loader):.6f} | Val Loss: {val_loss/len(val_loader):.6f}\")\n","metadata":{"execution":{"execution_failed":"2025-06-11T20:35:51.343Z","iopub.execute_input":"2025-06-11T19:24:27.918389Z","iopub.status.busy":"2025-06-11T19:24:27.917998Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport polars as pl\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# === CONFIG ===\nchunk_size = 25_000  # Adjust this depending on available memory\ntest_path = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n\n# === STORAGE ===\nsubmission_chunks = []\nrunning_id = 0\n\n# === CHUNKED PROCESSING LOOP ===\nfor i, df_chunk in enumerate(pl.read_parquet(test_path).iter_slices(n_rows=chunk_size)):\n    print(f\" Processing chunk {i+1}\")\n\n    # Drop label (all zeros in test set)\n    if \"label\" in df_chunk.columns:\n        df_chunk = df_chunk.drop(\"label\")\n\n    # Convert to NumPy and clean\n    X_chunk = df_chunk.to_numpy()\n    X_chunk[np.isinf(X_chunk)] = np.nan\n\n    # Apply valid column filter\n    X_chunk = X_chunk[:, valid_cols]\n\n    # Impute missing\n    inds = np.where(np.isnan(X_chunk))\n    X_chunk[inds] = np.take(col_means, inds[1])\n\n    # Scale\n    X_chunk_scaled = scaler.transform(X_chunk)\n\n    # Create rolling windows\n    X_chunk_seq = [\n        X_chunk_scaled[j:j + LOOKBACK]\n        for j in range(len(X_chunk_scaled) - LOOKBACK - HORIZON)\n    ]\n\n    if not X_chunk_seq:\n        continue\n\n    X_chunk_seq = np.stack(X_chunk_seq)\n    X_chunk_tensor = torch.tensor(X_chunk_seq, dtype=torch.float32)\n    test_loader = DataLoader(TensorDataset(X_chunk_tensor), batch_size=32)\n\n    # Predict\n    model.eval()\n    chunk_preds = []\n    with torch.no_grad():\n        for (xb,) in test_loader:\n            xb = xb.to(device)\n            out = model(xb).cpu().numpy().squeeze()\n            chunk_preds.extend(out)\n\n    # Store predictions with global ID\n    chunk_df = pd.DataFrame({\n        \"ID\": np.arange(running_id, running_id + len(chunk_preds)),\n        \"prediction\": chunk_preds\n    })\n    submission_chunks.append(chunk_df)\n    running_id += len(chunk_preds)\n\n# === FINAL SUBMISSION FILE ===\nsubmission_df = pd.concat(submission_chunks, ignore_index=True)\nsubmission_df.to_csv(\"3chunkedcryptopredsubmission.csv\", index=False)\nprint(\" Submission saved to 'cunkedcryptopredsubmission.csv' with shape:\", submission_df.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nval_preds = []\nval_targets = []\n\nwith torch.no_grad():\n    for xb, yb in val_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        preds = model(xb).squeeze().cpu().numpy()\n        targets = yb.squeeze().cpu().numpy()\n        val_preds.extend(preds)\n        val_targets.extend(targets)\n\nval_preds = np.array(val_preds)\nval_targets = np.array(val_targets)\n","metadata":{"execution":{"execution_failed":"2025-06-11T20:35:51.343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nmse = mean_squared_error(val_targets, val_preds)\nmae = mean_absolute_error(val_targets, val_preds)\nr2  = r2_score(val_targets, val_preds)\n\nprint(f\"Validation MSE:  {mse:.6f}\")\nprint(f\"Validation MAE:  {mae:.6f}\")\nprint(f\"Validation R²:   {r2:.4f}\")\n","metadata":{"execution":{"execution_failed":"2025-06-11T20:35:51.343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"direction_acc = np.mean(np.sign(val_preds) == np.sign(val_targets))\nprint(f\"Directional Accuracy: {direction_acc:.2%}\")\n","metadata":{"execution":{"execution_failed":"2025-06-11T20:35:51.343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 4))\nplt.plot(val_targets[:300], label=\"True\", alpha=0.7)\nplt.plot(val_preds[:300], label=\"Predicted\", alpha=0.7)\nplt.title(\"Validation Predictions vs Ground Truth\")\nplt.xlabel(\"Time step\")\nplt.ylabel(\"Label\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"execution_failed":"2025-06-11T20:35:51.343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.stats import pearsonr\n\nmodel.eval()\npreds, labels = [], []\n\nwith torch.no_grad():\n    for xb, yb in val_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        pr = model(xb).cpu().numpy()\n        lb = yb.cpu().numpy()\n        preds.extend(pr.squeeze())\n        labels.extend(lb.squeeze())\n\npearson_val = pearsonr(preds, labels)[0]\nprint(f\" Pearson on validation set: {pearson_val:.6f}\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom sklearn.preprocessing import StandardScaler\n\n# Create a synthetic sinusoidal dataset for demo\n\n# Parameters for the synthetic data\nN = 8192\nt = np.arange(N)\nfreq = 0.05\namplitude = 1.0\nnoise_std = 0.25\n\n# Sinusoidal signal with noise\nsignal = amplitude * np.sin(2 * np.pi * freq * t) + np.random.normal(0, noise_std, N)\n\n# Prepare features and targets using the same windowing as before\nLOOKBACK = 45\nHORIZON = 10\n\ndef make_windows(X, y, lookback=LOOKBACK, horizon=HORIZON):\n    Xs, Ys = [], []\n    for i in range(len(X) - lookback - horizon):\n        signal_window = X[i:i+lookback]\n        pos_window    = np.linspace(0, 1, lookback)  # normalized position\n        stacked       = np.stack([signal_window, pos_window], axis=-1)  # shape: (L, 2)\n        Xs.append(stacked)\n\n        future_val = y[i + lookback + horizon - 1]\n        last_val   = y[i + lookback - 1]\n        Ys.append(future_val - last_val)\n    return np.stack(Xs), np.array(Ys)\n\n\n\n\nX_demo, y_demo = make_windows(signal, signal)\n\n# Standardize\nscaler_demo = StandardScaler()\nX_demo_flat = X_demo.reshape(-1, X_demo.shape[-1])\nX_demo_scaled = scaler_demo.fit_transform(X_demo_flat).reshape(X_demo.shape)\ny_demo_scaled = scaler_demo.fit_transform(y_demo.reshape(-1, 1)).flatten()\n\n# Torch dataset and loader\nclass DemoDataset(torch.utils.data.Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ndemo_dataset = DemoDataset(X_demo_scaled, y_demo_scaled)\ndemo_loader = DataLoader(demo_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:06:13.556412Z","iopub.execute_input":"2025-06-17T22:06:13.557443Z","iopub.status.idle":"2025-06-17T22:06:13.784845Z","shell.execute_reply.started":"2025-06-17T22:06:13.557413Z","shell.execute_reply":"2025-06-17T22:06:13.784069Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------  Multi-Step Rollout Training Loop -----------------\nN_ROLL         = 5  # predict 10 steps into the future\ndemo_model     = Transformer(input_dim=2).to(device)\ndemo_loss_fn   = nn.MSELoss()\ndemo_optimizer = torch.optim.AdamW(demo_model.parameters(), lr=1e-5)\nmax_grad_norm  = 0.5\ndemo_epochs    = 25\n\nfor epoch in range(demo_epochs):\n    demo_model.train()\n    total_loss = 0.0\n\n    for xb, yb in demo_loader:              # xb: (B, L, 2), yb: (B, 1)\n        xb, yb = xb.to(device), yb.to(device)\n\n        # Initialize current window\n        current_window = xb.clone()         # shape: (B, L, 2)\n        future_deltas = []\n        last_val = xb[:, -1, 0]             # last signal value in window\n\n        preds_all = []\n\n        for step in range(N_ROLL):\n            pred_delta = demo_model(current_window).squeeze(1)  # (B,)\n\n            # Store prediction\n            preds_all.append(pred_delta)\n\n            # Compute next value (unroll)\n            next_val = last_val + pred_delta                   # (B,)\n\n            # Build new row: [next_val, pos=1.0]\n            next_row = torch.stack([next_val, torch.ones_like(next_val)], dim=-1)  # (B, 2)\n            next_row = next_row.unsqueeze(1)  # (B, 1, 2)\n\n            # Roll window forward\n            current_window = torch.cat([current_window[:, 1:], next_row], dim=1)\n            last_val = next_val.detach()\n\n        # Stack predicted deltas: shape (B, N_ROLL)\n        preds_all = torch.stack(preds_all, dim=1)  # (B, N_ROLL)\n\n        # Build ground truth deltas: advance yb by N_ROLL targets\n        true_deltas = []\n        start_idx = epoch * len(demo_loader.dataset) + 0  # just reuses the original delta from y_demo\n        for b in range(xb.size(0)):\n            future_deltas = []\n            ref_idx = b + xb.size(1)  # starting at last point\n            for step in range(N_ROLL):\n                idx = ref_idx + step * HORIZON\n                if idx + HORIZON >= len(signal): break\n                future_val = signal[idx + HORIZON]\n                last_val   = signal[idx]\n                delta = future_val - last_val\n                future_deltas.append(delta)\n            padded = future_deltas + [0.0] * (N_ROLL - len(future_deltas))\n            true_deltas.append(padded)\n\n        true_deltas = torch.tensor(true_deltas, dtype=torch.float32).to(device)  # (B, N_ROLL)\n\n        # Compute loss\n        loss = demo_loss_fn(preds_all, true_deltas)\n        demo_optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(demo_model.parameters(), max_grad_norm)\n        demo_optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(demo_loader)\n    print(f\"Epoch {epoch+1:2d}/{demo_epochs} | Rollout Loss: {avg_loss:.6f}\")\n# ---------------------------------------------------------------------\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T22:06:16.757063Z","iopub.execute_input":"2025-06-17T22:06:16.757638Z","iopub.status.idle":"2025-06-17T23:00:26.896559Z","shell.execute_reply.started":"2025-06-17T22:06:16.757616Z","shell.execute_reply":"2025-06-17T23:00:26.895838Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n# ------------------------------------------------------------\n# helper functions that respect the StandardScaler you trained\n\ndef build_raw_window(start_idx):\n    \"\"\"\n    returns ndarray (LOOKBACK, 2)\n    [:,0] = raw signal value\n    [:,1] = pos in [0,1]\n    \"\"\"\n    sig  = signal[start_idx : start_idx + LOOKBACK]\n    pos  = np.linspace(0, 1, LOOKBACK)\n    return np.stack([sig, pos], axis=-1)\n\n# ------------------------------------------------------------\ndef scale_batch(raw_np_window):\n    \"\"\"\n    raw_np_window : (1, L, 2)  [signal, pos]\n    scales column 0, leaves column 1 intact\n    \"\"\"\n    sig = raw_np_window[..., 0:1].reshape(-1, 1)\n    sig_scaled = scaler_demo.transform(sig).reshape(1, LOOKBACK, 1)\n\n    scaled_window = np.concatenate([sig_scaled, raw_np_window[...,1:2]], axis=-1)\n    return torch.tensor(scaled_window, dtype=torch.float32, device=device)\n\ndef unscale_val(z):\n    \"\"\"\n    z : scalar or 1-D NumPy array in scaled space  ->  raw scalar\n    \"\"\"\n    return scaler_demo.inverse_transform(np.array(z, ndmin=2))[0, 0]\n\n# ----------------------------------------------------------------\n# autoregressive rollout\n\nseed_idx  = 100\nnum_steps = 100\n\nraw_window = build_raw_window(seed_idx)                # (L,2)\npreds = []\n\ndemo_model.eval()\n\nfor _ in range(num_steps):\n    xb = scale_batch(raw_window[np.newaxis, ...])      # (1,L,2)\n\n    with torch.no_grad():\n        delta_scaled = demo_model(xb).cpu().item()     # scalar in scaled space\n\n    delta_raw = unscale_val(delta_scaled)\n    next_sig  = raw_window[-1, 0] + delta_raw          # absolute prediction\n\n    preds.append(next_sig)\n\n    # slide: new row = [next_sig , 1.0]  (pos==1), then re-normalise positions\n    new_row  = np.array([next_sig, 1.0])\n    raw_window = np.vstack([raw_window[1:], new_row])\n\n    # re-normalise pos column to 0-1\n    raw_window[:, 1] = np.linspace(0, 1, LOOKBACK)\n\n\n# ----------------------------------------------------------------\n# plot\n# ----------------------------------------------------------------\nplt.figure(figsize=(14, 5))\n\n# true future (raw signal)\nplt.plot(\n    range(seed_idx + LOOKBACK, seed_idx + LOOKBACK + num_steps),\n    signal[seed_idx + LOOKBACK : seed_idx + LOOKBACK + num_steps],\n    label=\"True Future\", color=\"tab:blue\"\n)\n\n# model predictions\nplt.plot(\n    range(seed_idx + LOOKBACK, seed_idx + LOOKBACK + num_steps),\n    preds,\n    label=\"Model Prediction\", color=\"tab:orange\"\n)\n\n# seed window\nplt.plot(\n    range(seed_idx, seed_idx + LOOKBACK),\n    signal[seed_idx : seed_idx + LOOKBACK],\n    label=\"Seed Window\", color=\"tab:green\", linestyle=\"dashed\"\n)\n\nplt.title(\"Autoregressive Inference: Predicting Future Timesteps w/ Transformer\")\nplt.xlabel(\"Timestep\")\nplt.ylabel(\"Label\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-06-17T23:00:26.898043Z","iopub.execute_input":"2025-06-17T23:00:26.898304Z","iopub.status.idle":"2025-06-17T23:00:27.717208Z","shell.execute_reply.started":"2025-06-17T23:00:26.898276Z","shell.execute_reply":"2025-06-17T23:00:27.716473Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------  Multi-Step Rollout Training Loop -----------------\nN_ROLL         = 5  # predict 10 steps into the future\ndemo_model     = LazyAttentionSSM(input_dim=2).to(device)\ndemo_loss_fn   = nn.MSELoss()\ndemo_optimizer = torch.optim.AdamW(demo_model.parameters(), lr=1e-5)\nmax_grad_norm  = 0.5\ndemo_epochs    = 25\n\nfor epoch in range(demo_epochs):\n    demo_model.train()\n    total_loss = 0.0\n\n    for xb, yb in demo_loader:              # xb: (B, L, 2), yb: (B, 1)\n        xb, yb = xb.to(device), yb.to(device)\n\n        # Initialize current window\n        current_window = xb.clone()         # shape: (B, L, 2)\n        future_deltas = []\n        last_val = xb[:, -1, 0]             # last signal value in window\n\n        preds_all = []\n\n        for step in range(N_ROLL):\n            pred_delta = demo_model(current_window).squeeze(1)  # (B,)\n\n            # Store prediction\n            preds_all.append(pred_delta)\n\n            # Compute next value (unroll)\n            next_val = last_val + pred_delta                   # (B,)\n\n            # Build new row: [next_val, pos=1.0]\n            next_row = torch.stack([next_val, torch.ones_like(next_val)], dim=-1)  # (B, 2)\n            next_row = next_row.unsqueeze(1)  # (B, 1, 2)\n\n            # Roll window forward\n            current_window = torch.cat([current_window[:, 1:], next_row], dim=1)\n            last_val = next_val.detach()\n\n        # Stack predicted deltas: shape (B, N_ROLL)\n        preds_all = torch.stack(preds_all, dim=1)  # (B, N_ROLL)\n\n        # Build ground truth deltas: advance yb by N_ROLL targets\n        true_deltas = []\n        start_idx = epoch * len(demo_loader.dataset) + 0  # just reuses the original delta from y_demo\n        for b in range(xb.size(0)):\n            future_deltas = []\n            ref_idx = b + xb.size(1)  # starting at last point\n            for step in range(N_ROLL):\n                idx = ref_idx + step * HORIZON\n                if idx + HORIZON >= len(signal): break\n                future_val = signal[idx + HORIZON]\n                last_val   = signal[idx]\n                delta = future_val - last_val\n                future_deltas.append(delta)\n            padded = future_deltas + [0.0] * (N_ROLL - len(future_deltas))\n            true_deltas.append(padded)\n\n        true_deltas = torch.tensor(true_deltas, dtype=torch.float32).to(device)  # (B, N_ROLL)\n\n        # Compute loss\n        loss = demo_loss_fn(preds_all, true_deltas)\n        demo_optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(demo_model.parameters(), max_grad_norm)\n        demo_optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(demo_loader)\n    print(f\"Epoch {epoch+1:2d}/{demo_epochs} | Rollout Loss: {avg_loss:.6f}\")\n# ---------------------------------------------------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T23:00:27.717957Z","iopub.execute_input":"2025-06-17T23:00:27.718168Z","iopub.status.idle":"2025-06-17T23:58:55.790420Z","shell.execute_reply.started":"2025-06-17T23:00:27.718151Z","shell.execute_reply":"2025-06-17T23:58:55.789611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n# ------------------------------------------------------------\n# helper functions that respect the StandardScaler you trained\n\ndef build_raw_window(start_idx):\n    \"\"\"\n    returns ndarray (LOOKBACK, 2)\n    [:,0] = raw signal value\n    [:,1] = pos in [0,1]\n    \"\"\"\n    sig  = signal[start_idx : start_idx + LOOKBACK]\n    pos  = np.linspace(0, 1, LOOKBACK)\n    return np.stack([sig, pos], axis=-1)\n\n# ------------------------------------------------------------\ndef scale_batch(raw_np_window):\n    \"\"\"\n    raw_np_window : (1, L, 2)  [signal, pos]\n    scales column 0, leaves column 1 intact\n    \"\"\"\n    sig = raw_np_window[..., 0:1].reshape(-1, 1)\n    sig_scaled = scaler_demo.transform(sig).reshape(1, LOOKBACK, 1)\n\n    scaled_window = np.concatenate([sig_scaled, raw_np_window[...,1:2]], axis=-1)\n    return torch.tensor(scaled_window, dtype=torch.float32, device=device)\n\ndef unscale_val(z):\n    \"\"\"\n    z : scalar or 1-D NumPy array in scaled space  ->  raw scalar\n    \"\"\"\n    return scaler_demo.inverse_transform(np.array(z, ndmin=2))[0, 0]\n\n# ----------------------------------------------------------------\n# autoregressive rollout\n\nseed_idx  = 100\nnum_steps = 100\n\nraw_window = build_raw_window(seed_idx)                # (L,2)\npreds = []\n\ndemo_model.eval()\n\nfor _ in range(num_steps):\n    xb = scale_batch(raw_window[np.newaxis, ...])      # (1,L,2)\n\n    with torch.no_grad():\n        delta_scaled = demo_model(xb).cpu().item()     # scalar in scaled space\n\n    delta_raw = unscale_val(delta_scaled)\n    next_sig  = raw_window[-1, 0] + delta_raw          # absolute prediction\n\n    preds.append(next_sig)\n\n    # slide: new row = [next_sig , 1.0]  (pos==1), then re-normalise positions\n    new_row  = np.array([next_sig, 1.0])\n    raw_window = np.vstack([raw_window[1:], new_row])\n\n    # re-normalise pos column to 0-1\n    raw_window[:, 1] = np.linspace(0, 1, LOOKBACK)\n\n\n# ----------------------------------------------------------------\n# plot\n# ----------------------------------------------------------------\nplt.figure(figsize=(14, 5))\n\n# true future (raw signal)\nplt.plot(\n    range(seed_idx + LOOKBACK, seed_idx + LOOKBACK + num_steps),\n    signal[seed_idx + LOOKBACK : seed_idx + LOOKBACK + num_steps],\n    label=\"True Future\", color=\"tab:blue\"\n)\n\n# model predictions\nplt.plot(\n    range(seed_idx + LOOKBACK, seed_idx + LOOKBACK + num_steps),\n    preds,\n    label=\"Model Prediction\", color=\"tab:orange\"\n)\n\n# seed window\nplt.plot(\n    range(seed_idx, seed_idx + LOOKBACK),\n    signal[seed_idx : seed_idx + LOOKBACK],\n    label=\"Seed Window\", color=\"tab:green\", linestyle=\"dashed\"\n)\n\nplt.title(\"Autoregressive Inference: Predicting Future Timesteps w/ LazyAttentionSSM\")\nplt.xlabel(\"Timestep\")\nplt.ylabel(\"Label\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T23:58:55.792002Z","iopub.execute_input":"2025-06-17T23:58:55.792245Z","iopub.status.idle":"2025-06-17T23:58:56.642001Z","shell.execute_reply.started":"2025-06-17T23:58:55.792229Z","shell.execute_reply":"2025-06-17T23:58:56.641367Z"}},"outputs":[],"execution_count":null}]}